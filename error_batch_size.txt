
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
class_weights: [2.2222223 0.7751938 0.7936508]
{'loss': 1.0808, 'grad_norm': 4.2278218269348145, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}           
 33%|█████████████████████████▋                                                   | 50/150 [00:12<00:24,  4.13it/sTraceback (most recent call last):███████████████████████████████████████████████ | 164/166 [00:11<00:00, 13.22it/s]
  File "/Users/stefanliemawan/codefiles/kul/bias/article-level-bias-classification/train/train_sliding_window.py", line 151, in <module>
    functions.train(
  File "/Users/stefanliemawan/codefiles/kul/bias/article-level-bias-classification/train/utils/functions.py", line 149, in train
    trainer.train()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer.py", line 2049, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer.py", line 2412, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer.py", line 3229, in evaluate
    output = eval_loop(
             ^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer.py", line 3444, in evaluation_loop
    preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 125, in nested_concat
    return torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Caskroom/miniconda/base/envs/bias/lib/python3.12/site-packages/transformers/trainer_pt_utils.py", line 83, in torch_pad_and_concatenate
    if len(tensor1.shape) == 1 or tensor1.shape[1] == tensor2.shape[1]:
                                                      ~~~~~~~~~~~~~^^^
IndexError: tuple index out of range


error if BATCH_SIZE is lower than 8, probably something in the eval loop, pred list is too small or something idk