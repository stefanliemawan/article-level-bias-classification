\chapter{Background Information and Literature Review}
\label{cha:2}

This chapter provides background information on media bias, introduces general machine learning concepts, and covers relevant Natural Language Processing (NLP) techniques. Additionally, related works on document classification and media bias classification are reviewed.


\section{Media Bias}

Allsides \cite{allsides-2022-bias-definition} defines media bias as "The tendency of news media to report in a way that reinforces a viewpoint, world-view, preference, political ideology, corporate or financial interests, moral framework, or policy inclination, instead of reporting in an objective way (simply describing the facts)". Media bias has existed and been researched since the 1950s \cite{white-1950-case-study-selection-news}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{images/bias-types-taxonomy.png}
    \caption{Media bias types as defined in The Media Bias Taxonomy \cite{spinde-2024-taxonomy}}
    \label{fig:media-bias-taxonomy}
\end{figure}

Many works and authors have attempted to categorise media bias based on its types and characteristics \cite{rodrigo-2024-systematic-review-media-bias,eberl-2017-bias-political,spinde-2024-taxonomy,allsides-media-bias-types}, each with their own interpretations. However, none of these categorisations align with each other, making universally accepted characteristics of media bias difficult to achieve \cite{rodrigo-2024-systematic-review-media-bias}. Thus, this project will specifically follow media bias categorisation according to The Media Bias Taxonomy by Spinde et al. (Figure \ref{fig:media-bias-taxonomy}). Particularly, the main focus is on \textbf{text-level context bias}, which pertains to the context of a text and the manner in which it is conveyed \cite{spinde-2024-taxonomy}.

\begin{figure}[htbp]
    \centering
    \fbox{\includegraphics[width=0.9\linewidth]{images/phrasing_bias_example.png}}
    \fbox{\includegraphics[width=0.9\linewidth]{images/spin_bias_example.png}}
    \fbox{\includegraphics[width=0.9\linewidth]{images/statement_bias_example.png}}
    \caption{Example of phrasing bias (top), spin bias (middle), and statement bias (bottom) \cite{allsides-media-bias-types}}
    \label{fig:bias-examples}
\end{figure}

Figure \ref{fig:bias-examples} shows examples taken from the Allsides website \cite{allsides-media-bias-types} referring to the three types of text-level context bias: phrasing bias, spin bias, and statement bias. \textit{Phrasing bias} is characterised by the use of provocative, inflammatory, or non-neutral language, using words that may evoke specific feelings or emotions in the reader \cite{spinde-2024-taxonomy,hube-2019-neural-biased-language}. The top article snippet in Figure \ref{fig:bias-examples} shows the phrase "...it's going to be a bloodbath". The phrase can be considered phrasing bias as it evokes a violent image and may lead readers to perceive the election as extremely chaotic or violent, even though it is not literal. \textit{Spin bias} is introduced when essential information is omitted from the narrative, or when irrelevant information is added instead \cite{spinde-2024-taxonomy}, often as an effort to craft a memorable story \cite{mullainathan-2002-media-bias}. The middle article in Figure \ref{fig:bias-examples} purposefully omitted the crucial information that the number of agencies reporting hate crime incidents has also increased. This creates a false narrative that hate crimes are on the rise, despite the possibility that the increase in reported incidents might be attributed to a higher number of reporting agencies. \textit{Statement bias} occurs when media personnel insert their personal views into the content, resulting in certain news being presented in a manner that is more or less favourable towards a particular view or position \cite{spinde-2024-taxonomy,d-alessio-2000-meta-analysis}. The sentence "He's a delicate snowflake" shown in the example (Figure \ref{fig:bias-examples} bottom article) is clearly a personal opinion of the author of the post.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/statistic_id1317019_consumers-witnessing-false-information-on-certain-topics-worldwide-2023.png}
    \caption{The rate of news consumers witnessing false or misleading information on several recent key topics in February 2023 \cite{reuters-2023-false-info}}
    \label{fig:consumers-witnessing-false-information-on-certain-topics-worldwide-2023}
\end{figure}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/statistic_id1462057_frequency-of-seeing-false-information-online-in-the-us-2023-by-age-group.png}
    \caption{How often false or misleading information is seen online in the United States as of April 2023 \cite{yougov-2023-frequency}.}
    \label{fig:frequency-of-seeing-false-information-online-in-the-us-2023-by-age-group}
\end{figure}

Media bias and misinformation are particularly prominent and visible within the United States, compared to other countries. Based on surveys from Reuters \cite{reuters-2023-false-info} and YouGov \cite{yougov-2023-frequency} (Figure \ref{fig:consumers-witnessing-false-information-on-certain-topics-worldwide-2023} and Figure \ref{fig:frequency-of-seeing-false-information-online-in-the-us-2023-by-age-group}), the United States (US) is shown to have the highest rate of encountering false or misleading information related to politics, COVID-19, and climate change. Nearly half of the respondents reported seeing such information in the week prior to the survey, with most adults across all age groups reporting seeing false or misleading information on a \textbf{daily} basis.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/statistic_id657090_ability-to-recognize-false-information-and-news-in-the-us-2023.png}
    \caption{Ability to recognise false information in the US \cite{yougov-2023-confidence}}
    \label{fig:ability-to-recognize-false-information-and-news-in-the-us-2023}
\end{figure}

Another similar survey by YouGov \cite{yougov-2023-confidence} (Figure \ref{fig:ability-to-recognize-false-information-and-news-in-the-us-2023}) shows that as of April 2023, 25\% of respondents feel either only a little confident, not at all confident, or not sure in their ability to distinguish false news from real news in the US. These findings are alarming.

Furthermore, Trust in news media in the US is at an all-time low, declining consistently and significantly over the past 20 years \cite{pew-2021-partisan-divides, gallup-knight-2020-american-views, reuters-2023-digital-news-report}. Approximately half of Americans believe that the media is significantly responsible for the political divisions within the United States, with a growing number of Americans losing faith in the media's objectivity and perceiving it as actively engaging in ideological wars \cite{gallup-knight-2020-american-views}. Reuters Institute also reported less than half of their respondents (40\%) generally trust the majority of news sources, with the US ranked 29\textsuperscript{th} out of 40 countries (32\%) in terms of trust \cite{reuters-2023-digital-news-report,reuters-2023-trust} (full figure shown in Figure \ref{fig:trustworthiness-of-news-media-worldwide-2023}).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{images/statistic_id308468_trustworthiness-of-news-media-worldwide-2023.png}
    \caption{Trustworthiness of news media worldwide by country, as of February 2023 \cite{reuters-2023-trust}}
    \label{fig:trustworthiness-of-news-media-worldwide-2023}
\end{figure}

Considering the magnitude of this problem in the United States, and given that the majority of research and resources on media bias are typically focused on the US \cite{allsides, adfontes,rodrigo-2024-systematic-review-media-bias}, it is therefore both reasonable and practical for this project to focus on US-based articles and domains.


% Panagopoulos' study \cite{panagopoulos-2020} revealed systemic biases leaning towards Democratic candidates during national and state levels pre-election polls conducted during the 2020 U.S. general election cycle. 

% Rafail et al. \cite{rafail-2018-tea-party} examined 201,678 media documents from Tea Party organizations, Fox News, MSNBC, and 785 newspapers, revealing significant differences in how the Tea Party frames itself compared to how other media sources frame the movement, MSNBC portrays it as the worst aspect of the Republican Party, while Fox News sees it as the best, sharply in contrasts with how activists frame the movement as conservative but not strictly Republican, often clashing with Republican Party goals.

% Readers themselves are not exempt from bias, as they are known to prefer to pick, follow, and consume articles that align with their own beliefs and ideology, an issue known as filter bubble \cite{lim-2018-understanding} or selective exposure \cite{spinde-2024-taxonomy}. This incident reinforces existing biases and limits exposure to diverse perspectives, creating echo chambers that hinder critical thinking and informed decision-making. The combination of media bias and filter bubbles can distort reality, perpetuate misinformation, and deepen societal divisions.

\section{Machine Learning Concepts and Techniques}

\subsection{Text Representation}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/bow_illustration.png}
    \caption{An illustration of how Bag-of-Words work \cite{rahul-2023-bow-medium}}
    \label{fig:bow_illustration}
\end{figure}

\textbf{Bag-of-Words (BoW)} is one of the most straightforward techniques to represent text. It works by counting the occurrences of each word for each instance and ignoring the order of the words and grammatical structure \cite{qader-2019-bow}. A simple illustration is shown in Figure \ref{fig:bow_illustration}. The biggest advantage of this technique lies in its conceptual simplicity and low computation cost. However, word order and semantics are completely disregarded, and it can be problematic when common words (like stop-words) dominate the representation.

Thus, \textbf{Term Frequency-Inverse Document Frequency (TF-IDF)} can be considered an enhanced version of BoW. It evaluates the importance of a word in a document relative to a collection of documents (corpus). Term Frequency (TF) calculates the number of times a term appears in a document, normalised by the total number of terms in the document. Inverse Document Frequency (IDF) \cite{jones-2004-idf} calculates how much information a word provides by measuring its rarity across the entire corpus. Specifically, IDF is calculated as the logarithm of the total number of documents divided by the number of documents containing the term. The combination of TF and IDF helps to give higher weights to terms that are rare and potentially more informative in the context of a document, rather than to terms that are common across many documents. The TF-IDF formula is given by:
\begin{equation}
    \text{TF-IDF}(t, d, D) = \text{TF}(t, d) \times \text{IDF}(t, D)
\end{equation}
\begin{equation}
    \text{TF}(t, d) = \frac{f(t, d)}{\sum_{t' \in d} f(t', d)}
\end{equation}
\begin{equation}
    \text{IDF}(t, D) = \log \frac{|D|}{|\{d \in D \mid t \in d\}|}
\end{equation}
where \(\text{TF}(t, d)\) is the term frequency of the term \( t \) in document \( d \), and \(\text{IDF}(t, D)\) is the inverse document frequency of the term \( t \) in the document collection \( D \). Thus, \( f(t, d) \) denotes the frequency of term \( t \) in document \( d \), \( |D| \) is the total number of documents in the collection, and \( |\{d \in D \mid t \in d\}| \) is the number of documents containing the term \( t \).

Embeddings represent knowledge through low-dimensional vectors that integrate easily into modern machine learning models, which have been a crucial topic in NLP \cite{camacho-collados-2020-embeddings}. This approach gained significant popularity with the introduction of \textit{word2vec} and \textbf{Global Vectors for Word Representation (GloVE)} \cite{pennington-2014-glove} as methods to generate word embeddings \cite{mikolov-2013-embeddings}, which map each word to a fixed vector (visualised in Figure \ref{fig:word-embeddings}). Embeddings can be extended further to encode sentences and documents instead of words (sentence embeddings and document embeddings). Paragraph vector, or \textit(doc2vec), is a continuation from \textit{word2vec}, which learns fixed-length feature representations from text segments of varying lengths, including sentences, paragraphs, and documents \cite{mikolov-2014-doc2vec}. However, word embeddings and BoW have also been shown to perform better than paragraph vector models for sentence classification \cite{white-2015-how-well-sentence-embeddings}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{images/word_embeddings.png}
    \caption{Word embeddings visualisation \cite{narayanan-2019-word-embeddings}}
    \label{fig:word-embeddings}
\end{figure}


Nevertheless, word embeddings have an important limitation. Since every word is mapped into a fixed single vector, word embeddings are considered static or non-contextualised, therefore, unable to distinguish between different meanings of a word \cite{camacho-collados-2020-embeddings}. Words such as 'break,' 'cut,' or 'duck' can have multiple meanings depending on their context, and thus require better modelling to achieve an accurate semantic representation. This problem is solved by contextualised word embeddings, which assign each word with a representation based on its context, allowing it to capture usage in different contexts and encode knowledge that can be transferred across languages \cite{liu-2020-survey-contextual-embeddings}. The embedding is typically encoded dynamically through the use of a pre-trained language model, illustrated in Figure \ref{fig:contextualised-word-embeddings}.

% OOV?

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{images/contextualised_word_embeddings.png}
    \caption{An illustration of contextualised word embeddings, a language model is used to analyse the context of the target word and creates a dynamic representation. \cite{camacho-collados-2020-embeddings}}
    \label{fig:contextualised-word-embeddings}
\end{figure}


\subsection{Neural Networks}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{images/mlp.png}
    \caption{MultiLayer Perceptron visualisation \cite{perez-enciso-2019-guide}}
    \label{fig:mlp}
\end{figure}

Neural Networks or Artificial Neural Networks (ANNs) saw a resurgence of interest after the development of a back-propagation algorithm in 1986 \cite{rumelhart-1986-ann}, which made training multi-layer networks feasible and practical. A neural network is composed of nodes, known as neurons, which are connected to each other and arranged in layers. The network uses the back-propagation algorithm to learn from errors and continuously enhance its performance, by minimising the discrepancy between the target output and the actual output using gradient descent \cite{popescue-2009-mlp}. Neurons are typically followed by an activation function, commonly the Rectified Linear Unit (ReLU), which is the component responsible for introducing non-linearity into the model and allows the network to learn and represent complex patterns.

The weighted sum (\( \mathbf{z} \)) in a hidden layer of a neural network is computed as follows (Equation \eqref{eq:z}):
\begin{equation}
    \label{eq:z}
    \mathbf{z} = \mathbf{W}\mathbf{x} + \mathbf{b}
\end{equation} where \( \mathbf{x} \) is the input vector, \( \mathbf{W} \) is the weight matrix, \( \mathbf{b} \) is the bias vector. After computing \( \mathbf{z} \), an activation function \( f \) is applied element-wise to produce the output \( \mathbf{h} \) (Equation \eqref{eq:h}):

\begin{equation}
    \label{eq:h}
    \mathbf{h} = f(\mathbf{z})
\end{equation}

\textbf{A MultiLayer Perceptron (MLP)} is a fully connected ANN that consists of single or multiple hidden layers, illustrated in Figure \ref{fig:mlp}. Hidden layers refer to the collection of neurons between the input and output layers, transforming data from layer to layer \cite{uzair-2020-hidden-layers}. MLP is widely used due to its ability to approximate complex functions that are beyond the capability of simple linear models \cite{popescue-2009-mlp}.

\subsection{Long Short-Term Memory (LSTM)}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{images/lstm.jpeg}
    \caption{LSTM architecture \cite{rahman-2023-lstm-networks}}
    \label{fig:lstm}
\end{figure}

effectively capture long-term dependencies in sequential data

LSTM \cite{hochreiter-1997-lstm} is a type of Recurrent Neural Network (RNN) designed to overcome the vanishing gradient problem and model long-term dependencies in sequential data. It incorporates two fundamental components: memory cells and gates. Memory cells maintain a cell state, which can store information over long sequences and allows the model to retain information for longer durations compared to traditional RNNs. Gates control the flow of information into and out of the memory cell, controlled by sigmoid and tanh activation functions, which regulate the information flow based on the input data and the current state. Figure \ref{fig:lstm} shows the full architecture of an LSTM block.

Bi-LSTM (Bidirectional Long Short-Term Memory) extends the LSTM (Long Short-Term Memory) by processing the given input sequence in both forward and backward directions. A Bi-LSTM layer consists of two separate LSTM layers: one for the forward pass and another for the backward pass. The outputs from these two directions are then combined to form a single representation. This approach has been shown to be a powerful enhancement, outperforming regular LSTM \cite{graves-2005-bilstm}.

\subsection{Transformer and Large Language Model (LLM)}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\linewidth]{images/transformer.png}
    \caption{Transformer visualisation \cite{vaswani-2023-attention}}
    \label{fig:transformer}
\end{figure}

The Transformer has become the preferred architecture in NLP, particularly for pre-trained models, due to its capabilities \cite{lin-2022-survey-transformers}. Its architecture depends solely on attention mechanisms to identify global dependencies across input and output sequences, allowing for unprecedented levels of parallelisation instead of sequential processing \cite{vaswani-2023-attention}.

Attention is calculated by incorporating: \(\mathbf{Q}\) is the query matrix, \(\mathbf{K}\) is the key matrix, and \(\mathbf{V}\) is the value matrix, using the following formula \cite{vaswani-2023-attention}:

\begin{equation}
    \label{eq:attention}
    \text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left( \frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt{d_k}} \right) \mathbf{V}
\end{equation}
Additionally, multi-head attention is typically implemented in the transformer to enable the model to simultaneously attend to information from various representation subspaces at different positions \cite{vaswani-2023-attention}. This is defined as:
\begin{equation}
    \label{eq:multihead}
    \text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h) \mathbf{W}^O
\end{equation}
where each head is calculated as:
\begin{equation}
    \label{eq:head}
    \text{head}_i = \text{Attention}(\mathbf{Q} \mathbf{W}^Q_i, \mathbf{K} \mathbf{W}^K_i, \mathbf{V} \mathbf{W}^V_i)
\end{equation}


\textbf{Large Language Models (LLMs)} are artificial neural networks that utilise the transformer architecture, designed to understand and generate human language. They are trained on vast amounts of diverse text data using unsupervised learning techniques, often containing millions or even billions of parameters. Two of the most popular and widely used LLMs are \textbf{Bidirectional Encoder Representations from Transformers (BERT)} \cite{devlin-2019-bert}, comprised of 110 million parameters, and Generative Pre-trained Transformer (GPT), particularly GPT-4 \cite{openai-2024-gpt4}, which is reported to have an astonishing 1.76 trillion parameters, based on a report by SemiAnalysis in 2023 \cite{semianalysis-gpt4}. Additionally, \textbf{RoBERTa} \cite{liu-2019-roberta} (Robustly Optimized BERT Approach) refines BERT's approach by optimising its training procedures, using larger datasets and increased computational resources. These improvements result in better performance across various benchmarks compared to BERT.

As in the BERT original paper \cite{devlin-2019-bert}, pre-trained language models can be exploited for downstream tasks through two main approaches: \textbf{feature-based} and \textbf{fine-tuning}. Feature-based approach \cite{devlin-2019-bert} leverages a pre-trained model to extract embeddings or features from text and use them as input to other machine-learning models for various downstream tasks. Fine-tuning \cite{devlin-2019-bert} adjusts the model weights based on the training data for the downstream task, allowing the model to adapt its pre-trained representations to the specific requirements of the task.

Transformers and LLMs have sparked a revolution in the domain of Artificial Intelligence (AI), having achieved remarkable successes across diverse fields such as natural language processing, computer vision, and audio processing \cite{lin-2022-survey-transformers}. They have single-handedly catalysed the emergence of a new era in AI capabilities observed today, predicted to have an even greater influence than the industrial and digital revolutions combined \cite{makridakis-2017-ai-revolution}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{images/bert_finetuning.png}
    \caption{BERT pre-training and fine-tuning procedures \cite{devlin-2019-bert}}
    \label{fig:bert_finetuning}
\end{figure}


\subsection{MAGPIE and DA-RoBERTa}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{images/magpie.png}
    \caption{MAGPIE containing a pre-trained representation of various biases \cite{horych-2024-magpie}.}
    \label{fig:magpie}
\end{figure}

Multi-Task Media-Bias Analysis Generalization for Pre-Trained Identification of Expressions, or \textbf{MAGPIE} \cite{horych-2024-magpie}, is a large-scale, RoBERTa-based \cite{liu-2019-roberta}, multitask pre-training approach specifically designed for media bias detection, pre-fine-tuned on fifty-nine bias-related tasks covering a broad spectrum of biases. Pre-fine-tuning \cite{aghajanyan-2021-muppet} is a large-scale training phase that can be placed between language model pre-training and fine-tuning. It involves extensive multitask learning (MTL) \cite{caruana-1997-mtl} and aims to foster the development of representations that generalise more effectively across various tasks \cite{aghajanyan-2021-muppet}. Pre-fine-tuning allows multitask-approach such as MAGPIE to generalise better on various tasks related to media bias, enabling better performance on these tasks compared to single-task RoBERTa approach \cite{horych-2024-magpie}.

\textbf{DA-RoBERTa} (Domain-Adaptive-RoBERTa) \cite{krieger-2022-domain} is another RoBERTa-based model, pre-trained and tailored for the media bias domain. The model training approach focuses on detecting biased word choices and identifying sentence-level bias \cite{krieger-2022-domain}.

Unfortunately, both MAGPIE and DA-RoBERTa are trained for sentence-level bias and output binary classification (biased or unbiased). As a result, they cannot be directly fine-tuned for article-level media bias classification tasks. However, the models and their feature representations can still be utilised for a feature-based approach \cite{devlin-2019-bert}, leveraging their knowledge in the media bias domain.


\subsection{Chunking and Hierarchical Techniques}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}
        \tikzstyle{arrow} = [thick,->,>=stealth]
        \tikzstyle{chunk} = [rectangle, draw, fill=gray!20, font=\tiny, text width=0.6\linewidth, align=left]
        \tikzstyle{label} = [text centered,font=\footnotesize]

        \node[label] at (0, 1) {Text input};
        \node (input) [draw, align=left, text width=0.9\linewidth, font=\tiny, fill=brown!20] at (0, 0) {Nearly 190,000 people tried to illegally enter the United States from its southern border with Mexico in June – the highest number in more than 20 years, and as much as ten times the total recorded during some months under Trump. According to data from US Customs and Border Protection, June saw 188,829 illegal immigrants attempt to cross the border...};

        \node[chunk] (chunk1) [draw] at (-1, -1.5) {Nearly 190,000 people tried to illegally enter the United States from its southern border with Mexico in June};
        \node[chunk] (chunk2) [draw] at (-1, -2.5) {the highest number in more than 20 years, and as much as ten times the total recorded during some months under Trump};
        \node[chunk] (chunk3) [draw] at (-1, -3.5) {According to data from US Customs and Border Protection, June saw 188,829 illegal immigrants attempt to cross the border};

        \draw[arrow] (input.west) |- (chunk1.west);
        \draw[arrow] (input.west) |- (chunk2.west);
        \draw[arrow] (input.west) |- (chunk3.west);
    \end{tikzpicture}
    \caption{Illustration of chunking}
    \label{fig:chunking}
\end{figure}


\textbf{Chunking} is a technique used to break down text into smaller, more manageable units. This technique can be applied to segment documents into smaller paragraphs or sentences, as illustrated in Figure \ref{fig:chunking}, facilitating more efficient processing and analysis. After the process of chunking, a pooling operation is typically performed to retain information from the whole sequence. Commonly used pooling strategies include max-pooling, where only the maximum values are taken; \textbf{mean-pooling}, where the mean over all the representations of chunks is calculated; and \textbf{CLS-pooling}, where only the CLS representation (in BERT-like models) is retained while others are discarded.

\textbf{Hierarchical models} \cite{sun-2020-fine-tune} incorporate multiple levels of abstraction or granularity to capture complex relationships within data. These models are particularly useful when dealing with structured data that naturally fall into a hierarchical organisation, such as documents composed of paragraphs and sentences. Furthermore, \textbf{hierarchical transformer model} is a variant of the transformer architecture that incorporates hierarchical structures to handle long sequences more efficiently. These models process data at different levels, such as sentences within paragraphs, to capture hierarchical relationships. Figure \ref{fig:hi_transformer} shows an example of a hierarchical transformer model used to produce document embeddings by harnessing sentence-level and word-level information \cite{wu-2021-hi-transformer}.



\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{images/hi_transformer.png}
    \caption{An example of a hierarchical transformer model, Hi-Transformer \cite{wu-2021-hi-transformer}, to model long document by incorporating information on sentence and word level.}
    \label{fig:hi_transformer}
\end{figure}


\section{Literature Review}

This section will discuss related works within the domain of document classification, media bias classification, and article-level media bias classification.


\subsection{Document Classification}

Document classification refers to the task of assigning one or more labels to a document from a predefined set of categories \cite{wan-2019-long-length}. This task was first mentioned in 1963 \cite{borko-1963-auto-doc-classification}, with statistical text processing concepts and techniques defined earlier in the 1950s \cite{luhn-1958-business-intelligence-system}. In modern times, Convolutional Neural Networks (CNNs) \cite{afzal-deepdocclassifier,liu-2017-xmlcnn} have been conventionally implemented for this task. However, CNNs have largely been surpassed by more recent methods such as Hierarchical Attention Networks (HAN) \cite{yang-2016-han}, which use word and sentence-level attention to extract significant features from documents, and DocBERT \cite{adhikari-2019-docbert}, which leverages knowledge distillation from the BERT-large model.

A limitation of transformer-based approaches for document classification is that models such as BERT are only able to process a maximum of 512 input tokens \cite{devlin-2019-bert}. Therefore, additional techniques such as chunking or hierarchical approach are necessary to process longer sequences. There exist other LLMs that are designed specifically to handle longer sequences, such as Longformer \cite{beltagy-2020-longformer} and BigBird \cite{zaheer-2021-bigbird}. Longformer combines both global and local attention mechanisms \cite{beltagy-2020-longformer}, while BigBird extends the global and local attention with additional random attention \cite{zaheer-2021-bigbird}. However, Longformer has been reported to be inconsistent in the classification of long documents, performing only notably better than the baseline models (e.g. BERT of the first 512 tokens) on only two datasets \cite{park-2022-efficient}.

Therefore, chunking and hierarchical techniques have been implemented to combat the problem of handling long sequences. Pappagari et al. \cite{pappagari-2019-hierarchical} are among the first to apply the transformer architecture for long sequences classification, introducing chunking and propagation methods. Su et al. \cite{su-2021-classifying} used chunking methods in a hierarchical transformer model with 'CLS-Pooling' (as also described in \cite{adhikari-2019-docbert}) to extract representations on the document level for the task of clinical document classification. Khandve et al. \cite{khandve-2022-hierarchical-longdoc} also implemented a hierarchical model by combining BERT-encoded representations and Bi-LSTM layers for long document classification tasks.


\subsection{Media Bias Classification}

Article classification can be seen as a subset of document classification, focusing primarily on assigning articles into a specific set of categories \cite{dien-2019-article-classification}. In this project, articles refer to mostly news pieces published by media outlets. Most news articles typically range between 500 and 1200 words on average \cite{newswhip-2013-article-length}, shorter than many general applications of document classification. Media bias classification refers to the task of analysing and categorising media content to determine the presence and extent of bias. Thus, article-level media bias classification involves performing media bias classification on entire articles rather than on sentences or phrases.

\begin{figure}[htbp]
    \centering
    \fbox{
        \includegraphics[width=0.9\linewidth]{images/media_bias_dataset_overview.png}}
    \caption{Overview of available media bias datasets \cite{rodrigo-2024-systematic-review-media-bias}}
    \label{fig:media-bias-datasets-overview}
\end{figure}

Current available datasets for article-level and media bias classification often vary in formats or incorporate different types of bias \cite{rodrigo-2024-systematic-review-media-bias} (Figure \ref{fig:media-bias-datasets-overview}). Consequently, it is challenging to compare these datasets directly in terms of their quality and usefulness.

The \textbf{BASIL} dataset \cite{fan-2019-basil} is the most commonly used bias dataset, containing 300 articles with both article-level and phrase-level annotations. The \textbf{NLPCSS} \cite{chen-2020-nlpcss} dataset, with 6,964 articles annotated via Ad Fontes labels, includes article-level textual content with three bias labels (bias, neutral, or unknown).

The \textbf{NELA-GT-2022} dataset \cite{gruppi-2023-nela-gt-2022} includes 1,778,361 articles from 361 outlets, annotated with labels from the Media Bias/Fact Check (MBFC) \cite{mbfc} website. Despite its large size, the primary issue with this dataset is the ambiguity of its three labels: reliable, mixed, and unreliable. I argue that these labels lack clarity and fail to provide sufficient information about the annotated articles. The 'mixed' label, in particular, poses a challenge as it is unclear how to interpret articles categorised under this label. This lack of precision in classification undermines the utility of the dataset for rigorous analysis and research purposes. Similarly, the NLPCSS dataset faces the same issue.

The \textbf{BAT} dataset \cite{spinde-2023-bat} includes 6,345 articles from 321 outlets annotated with Ad Fontes labels. Unlike other datasets, the BAT dataset provides clear and precise labels with its bias and reliability scores for articles. However, the dataset lacks the textual content of the articles, requiring further extension by crawling the article content from the respective websites, a process that will be fully described in the next chapter. Additionally, the dataset also holds 175,807 comments and retweets related to the articles.

Other datasets shown in Figure \ref{fig:media-bias-datasets-overview} either have a political compass rating or are annotated at the sentence level, making them unsuitable for this project.

Past works on media bias classification typically use the BASIL dataset, operating on a sentence level and outputting binary results (either biased or not) \cite{maab-2023-lexical-bias-detection, maab-2023-target-aware, guo-2022-modeling, van-den-berg-2020-context,lee-2021-unifying,lei-2022-sentence,lei-2024-event-relation,krieger-2022-domain}, complemented by the lack of appropriate and adequate datasets with article-level annotations \cite{demidov-2023-political-bias-classification}.

Consequently, There are only a few existing works on article-level media bias classification, with most works focusing on detecting political bias (leaning-left, right, or centre) or ideology instead of purely media bias. Kulkarni et al. \cite{kulkarni-2018-multi-view} proposed a method that incorporates cues from the title, link structure, and content of articles to predict political ideology. Baly et al. \cite{baly-2020-we-can-detect-your-bias} adversarial media adaptation approach to detect political bias in news articles. Kim and Johnson \cite{kim-johnson-2022-close} proposed an MTL model (CLoSE) made of either a BERT-based or RoBERTa-based encoder, followed by a pooling layer to create sentence embeddings, which are then fed into a classifier to predict political bias. Chen et al. \cite{chen-2020-detecting-media-bias-gaussian} employed a Gaussian mixture model that exploits sentence-level bias information to detect article-level bias. Chen et al.'s definition and approach to media bias closely align with this project; however, it does not incorporate any transformer-based or State-of-the-Art (SOTA) methods.

\section{Key Takeaways}

While the NELA-GT-2022 \cite{gruppi-2023-nela-gt-2022} dataset contains significantly more articles than the BAT dataset \cite{spinde-2023-bat}, the lack of clarity in the labels of NELA-GT-2022 poses a major problem. Therefore, the BAT dataset is considered a more favourable option.

Although research in article-level media bias classification is currently limited, this chapter has reviewed several promising approaches from previous works in document classification that could be applied to this task. Combined with State-of-the-Art (SOTA) NLP techniques, these approaches could provide valuable insights into their effectiveness for article-level media bias classification.

The next chapter will provide a detailed discussion of the BAT dataset, while Chapter 4 will explore the proposed methods based on these promising approaches.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 