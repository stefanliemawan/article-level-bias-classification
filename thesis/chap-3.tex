\chapter{Literature Review}
\label{cha:3}

\section{Dataset}

Datasets for media bias (\cite{spinde-2021-babe, spinde-2023-bat, fan-2019-basil, chen-etal-2020-nlpcss}) often have different metrics and formats, covering different types of bias, and therefore pose a different set of challenges:
\begin{itemize}
    \item The BABE dataset \cite{spinde-2021-babe} is a 3700 rows of sentence-level, expert annotated dataset containing binary bias label (biased or non-biased) along with an opinion explaining the factuality of the sentence (ranging from \textit{entirely factual, somewhat factual, no agreement, expresses writer's opinion, etc}). While this is a good bias dataset, its main disadvantage is that it operates solely on the sentence level. Articles contains a huge number of sentences and one of the main problem within detecting on sentence-level is that multiple sentences within the same article could have opposite or different biases (I think there is a cite for this, I remember reading).
    \item The BASIL dataset \cite{fan-2019-basil} (300 articles) is the most commonly used bias dataset out there, containing 300 articles with both article-level and phrase-level annotations (contains one or more sentences. The obvious drawback of this dataset is the low amount of articles included as it is not nearly enough data to get a good working detection model, (find out more about this and cite?)
    \item The BAT \cite{spinde-2023-bat} dataset (6345 rows, AdFontes labels) is the most suitable for article-level bias detection as it supplies both bias-score and reliability-score for the whole article. However, the dataset itself does not supply textual content of the articles and therefore need to be extended, something that I have been working on as well during my Master's Thesis this and last year.
    \item NLPCSS \cite{chen-etal-2020-nlpcss} (6964 rows),  also annotated via AdFontes labels, containing article-level textual content with three bias labels (bias, neutral, or unknown). This one is also a good candidate for work in article-level granularity, however BAT dataset is richer in labels (scores) fluidity and additional metadata as it contains outlets information as well as twitter comments corresponding to each articles.
\end{itemize}

Another challenge can be correlated with the task of annotating media bias within a text. The traditional way is to hire experts and journalists to manually annotate and determine how biased the content is. As with \cite{spinde-2021-babe}, annotations are generally compiled and majority voted to achieve the final annotation given a particular text. It is important to use multiple annotators to minimise introducing another form of bias towards the dataset. Annotators' personal background moderately influenced their decisions and should be taken into consideration when building datasets, along with other factors such as topics, reading news habits, and honest mistakes \cite{spinde-2021-bias-words}. Clearly, this is not a cheap procedure.

Alternatively, websites such as Allsides and AdFontes have their own experts and annotations to which can be crawled and make use of (cite cite). However, they operate solely within the U.S., coverting U.S. media sources. To my knowledge, there is no other organisation that do what they do outside the U.S. or in a more global scale, at the same level. Therefore, building a dataset that is not only accurate, but also global and diverse would have massive benefits.

\begin{comment}
News Unfold: (NewsUnravel shows that a user-centric approach to media bias data collection can re- turn reliable data while being scalable and evaluated as easy to use. NewsUnravel demonstrates that feedback mechanisms are a promising strategy to reduce data collection expenses and continuously update datasets to changes in context.) (Our approach augments dataset quality by significantly increasing inter-annotator agreement by 26.31\% and improving classifier performance by 2.49\%)
\end{comment}

\section{Classification}

Current State-of-the-Art in media bias detection tend to employ neural or transformer-based approach, by fine-tuning or exploiting Large Language Models (cite cite). Encoder-based LLMs such as BERT and RoBERTA can be finetuned, zero or few shot learning can be applied to decoder-based LLMs for a downstream task of detecting media bias. While these can work pretty well (cite), these models are general purpose models tailored for general NLP tasks and therefore might lack the necessary attributes to precisely detect bias, in addition to the expensive computational cost for inference.

MAGPIE \cite{horych-2024-magpie} is the first large-scale, RoBERTa-based, multi-task learning (MTL) model dedicated for bias-related task, a promising approach for media bias detection and can be used to enhance the accuracy and efficiency of existing models. Using MAGPIE's context representation instead of BERT for media detection can potentially improve performance. However, currently the model only trained for sentence-level classification and also outputs binary result.

Many past works on automatic detection of media bias (cite cite) also typically operate on a sentence level and only output binary result (either biased or not) \cite{van-den-berg-2020-context, maab-2023-target-aware, lei-2024-sentence}. As media content are often delivered in the form of articles containing a number of paragraphs, detection at the article level is far more useful and desirable. More advanced methods could also include global-level spanning over multiple articles by implementing timeline, graphs, or other types of network to capture relationships among articles with same or similar topics.

Furthermore, The traditional approach of assigning only a single frame label to news articles remains overly simplistic, given that a standard news story often incorporates multiple viewpoints, arguments, or facets, each potentially carrying distinct connotations or framing \cite{vallejo-2023-connecting}. An integer label would be a slightly better solution to represent bias from a text, although it is still hardly ideal.

Additionally, it would be good to consider explainability of a model when classifying a bias, as we would need to not just get the result, but to understand why contents are considered bias. Existing media bias detection systems typically concentrate solely on predicting the likelihood of a certain text being biased, offering limited insights into the underlying reason behind the decision.

\section{Working with articles text}

Article texts length generally falls between medium to long sequences, as they are not as long as other types of documents (legal documents, clinical studies, etc.) but not short enough to be classified as short. Most research with long sequence generally have thousands of tokens while most news articles stay between 500 - 2000 tokens (find cite?).

The most straightforward approach of a standard fine-tuning of a BERT model is not necessarily effective as the model is only able to process a maximum of 512 tokens. Several techniques have been attempted to address this issue such as the sliding window techniques, CLS techniques \cite{su-2021-classifying}, where you exploit the 'CLS' token from a BERT embedding, and other more sophisticated models \cite{kulkarni-2018-multi-view}.

Additionally, there are other LLMs similar to BERT that are designed to handle longer sequences: Longformer (cite), BigBird (cite). However, most of these models have different architecture than the original BERT and therefore perform differently.
Advanced models such as Longformer, ToBERT, and CogLTX do not consistently surpass the baseline models in classification performance, and only performed notably better than the baseline models on only two datasets \cite{park-2022-efficient}. Based on my recent work with the BAT dataset, applying these larger models did not provide superior results compared to simply fine-tuning BERT on the initial 512 tokens. It's important to

% \section{Conclusion}
% The final section of the chapter gives an overview of the important results
% of this chapter. This implies that the introductory chapter and the
% concluding chapter don't need a conclusion.

\lipsum[66]

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
