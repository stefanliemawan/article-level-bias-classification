\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{adfontes-bias-reliability}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Methodology}{25}{chapter.4}\protected@file@percent }
\newlabel{cha:4}{{\M@TitleReference {4}{Methodology}}{25}{Methodology}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Dataset split}{25}{section.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Reliability scores are divided into four classes based on their values: Problematic, Questionable, Generally Reliable, and Reliable.\relax }}{25}{table.caption.27}\protected@file@percent }
\newlabel{table:label_split}{{\M@TitleReference {4.1}{Reliability scores are divided into four classes based on their values: Problematic, Questionable, Generally Reliable, and Reliable.\relax }}{25}{Reliability scores are divided into four classes based on their values: Problematic, Questionable, Generally Reliable, and Reliable.\relax }{table.caption.27}{}}
\citation{devlin-2019-bert}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Number of total samples in the dataset and number of samples for each class in train, test, and validation set\relax }}{26}{table.caption.28}\protected@file@percent }
\newlabel{table:dataset_split}{{\M@TitleReference {4.2}{Number of total samples in the dataset and number of samples for each class in train, test, and validation set\relax }}{26}{Number of total samples in the dataset and number of samples for each class in train, test, and validation set\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Features and Baselines}{26}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Proposed methods}{26}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Majority baseline based on outlet, every article here will be predicted as X since X is the most frequently observed class in outlet A\relax }}{27}{figure.caption.29}\protected@file@percent }
\newlabel{fig:majority_baseline}{{\M@TitleReference {4.1}{Majority baseline based on outlet, every article here will be predicted as X since X is the most frequently observed class in outlet A\relax }}{27}{Majority baseline based on outlet, every article here will be predicted as X since X is the most frequently observed class in outlet A\relax }{figure.caption.29}{}}
\citation{devlin-2019-bert}
\citation{devlin-2019-bert}
\citation{beltagy-2020-longformer}
\citation{zaheer-2021-bigbird}
\citation{devlin-2019-bert}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}BoW + MLP}{28}{subsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces BoW + MLP architecture. The input article is encoded as a bag of words, then feed into a single linear multilayer perceptron before softmax operation.\relax }}{28}{figure.caption.30}\protected@file@percent }
\newlabel{fig:bow_mlp_architecture}{{\M@TitleReference {4.2}{BoW + MLP architecture. The input article is encoded as a bag of words, then feed into a single linear multilayer perceptron before softmax operation.\relax }}{28}{BoW + MLP architecture. The input article is encoded as a bag of words, then feed into a single linear multilayer perceptron before softmax operation.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Fine-tuning}{28}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Chunked fine-tuning}{28}{subsection.4.3.3}\protected@file@percent }
\citation{su-2021-classifying}
\citation{sun-2020-fine-tune}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Chunked fine-tuning. The input article is split into chunks, each chunk is processed by the model as a mini batch, and the resulting logits are pooled before applying softmax operation.\relax }}{29}{figure.caption.31}\protected@file@percent }
\newlabel{fig:chunk_bert_finetuning}{{\M@TitleReference {4.3}{Chunked fine-tuning. The input article is split into chunks, each chunk is processed by the model as a mini batch, and the resulting logits are pooled before applying softmax operation.\relax }}{29}{Chunked fine-tuning. The input article is split into chunks, each chunk is processed by the model as a mini batch, and the resulting logits are pooled before applying softmax operation.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Hierarchical Transformer}{29}{subsection.4.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Hierarchical transformer model architecture.\relax }}{30}{figure.caption.32}\protected@file@percent }
\newlabel{fig:hi_model}{{\M@TitleReference {4.4}{Hierarchical transformer model architecture.\relax }}{30}{Hierarchical transformer model architecture.\relax }{figure.caption.32}{}}
\citation{barbera-2021-article-classification}
\citation{devlin-2019-bert}
\citation{krieger-2022-domain}
\citation{horych-2024-magpie}
\citation{agarap-2018-relu}
\citation{khandve-2022-hierarchical-longdoc}
\citation{van-1995-python}
\citation{paszke-2017-pytorch}
\citation{wolf-2020-huggingface}
\citation{devlin-2019-bert}
\citation{loshchilov-2019-adamw}
\citation{alkhawaldeh-2023-challenges}
\citation{pedregosa-2011-scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Training details}{31}{section.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Class weights in the training set\relax }}{32}{figure.caption.33}\protected@file@percent }
\newlabel{fig:class_weights}{{\M@TitleReference {4.5}{Class weights in the training set\relax }}{32}{Class weights in the training set\relax }{figure.caption.33}{}}
\@setckpt{chap-4}{
\setcounter{page}{33}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{37}
\setcounter{lastsheet}{58}
\setcounter{lastpage}{54}
\setcounter{figure}{5}
\setcounter{lofdepth}{1}
\setcounter{table}{2}
\setcounter{lotdepth}{1}
\setcounter{section@level}{1}
\setcounter{Item}{4}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{19}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
}
