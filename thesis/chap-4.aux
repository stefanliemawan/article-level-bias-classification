\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{adfontes-bias-reliability}
\citation{otero-2021-adfontes-methodology}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Methodology}{31}{chapter.4}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{cha:4}{{\M@TitleReference {4}{Methodology}}{31}{Methodology}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Dataset split}{31}{section.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Reliability scores are divided into four classes based on their values: Problematic, Questionable, Generally Reliable, and Reliable.\relax }}{31}{table.caption.37}\protected@file@percent }
\newlabel{table:label_split}{{\M@TitleReference {4.1}{Reliability scores are divided into four classes based on their values: Problematic, Questionable, Generally Reliable, and Reliable.\relax }}{31}{Reliability scores are divided into four classes based on their values: Problematic, Questionable, Generally Reliable, and Reliable.\relax }{table.caption.37}{}}
\citation{devlin-2019-bert}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Number of total samples in the dataset and number of samples for each class in train, test, and validation set\relax }}{32}{table.caption.38}\protected@file@percent }
\newlabel{table:dataset_split}{{\M@TitleReference {4.2}{Number of total samples in the dataset and number of samples for each class in train, test, and validation set\relax }}{32}{Number of total samples in the dataset and number of samples for each class in train, test, and validation set\relax }{table.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Features and Baselines}{32}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Proposed methods}{32}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Majority baseline based on outlet, every article here will be predicted as X since X is the most frequently observed class in outlet A\relax }}{33}{figure.caption.39}\protected@file@percent }
\newlabel{fig:majority_baseline}{{\M@TitleReference {4.1}{Majority baseline based on outlet, every article here will be predicted as X since X is the most frequently observed class in outlet A\relax }}{33}{Majority baseline based on outlet, every article here will be predicted as X since X is the most frequently observed class in outlet A\relax }{figure.caption.39}{}}
\citation{devlin-2019-bert}
\citation{devlin-2019-bert}
\citation{beltagy-2020-longformer}
\citation{zaheer-2021-bigbird}
\citation{devlin-2019-bert}
\citation{wu-2021-hi-transformer}
\citation{kulkarni-2018-multi-view}
\citation{su-2021-classifying}
\citation{khandve-2022-hierarchical-longdoc}
\citation{pappagari-2019-hierarchical}
\citation{yang-2016-han}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}BoW + MLP}{34}{subsection.4.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces BoW + MLP architecture. The input article is encoded as a bag of words, then fed into a single linear multilayer perceptron before softmax operation.\relax }}{34}{figure.caption.40}\protected@file@percent }
\newlabel{fig:bow_mlp_architecture}{{\M@TitleReference {4.2}{BoW + MLP architecture. The input article is encoded as a bag of words, then fed into a single linear multilayer perceptron before softmax operation.\relax }}{34}{BoW + MLP architecture. The input article is encoded as a bag of words, then fed into a single linear multilayer perceptron before softmax operation.\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Fine-tuning}{34}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Chunked fine-tuning}{34}{subsection.4.3.3}\protected@file@percent }
\citation{su-2021-classifying}
\citation{sun-2020-fine-tune}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Chunked fine-tuning. The input article is split into chunks, each chunk is processed by the model as a mini batch, and the resulting logits are pooled before applying softmax operation.\relax }}{35}{figure.caption.41}\protected@file@percent }
\newlabel{fig:chunk_bert_finetuning}{{\M@TitleReference {4.3}{Chunked fine-tuning. The input article is split into chunks, each chunk is processed by the model as a mini batch, and the resulting logits are pooled before applying softmax operation.\relax }}{35}{Chunked fine-tuning. The input article is split into chunks, each chunk is processed by the model as a mini batch, and the resulting logits are pooled before applying softmax operation.\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Hierarchical Transformer}{35}{subsection.4.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Hierarchical transformer model architecture.\relax }}{36}{figure.caption.42}\protected@file@percent }
\newlabel{fig:hi_model}{{\M@TitleReference {4.4}{Hierarchical transformer model architecture.\relax }}{36}{Hierarchical transformer model architecture.\relax }{figure.caption.42}{}}
\citation{barbera-2021-article-classification}
\citation{devlin-2019-bert}
\citation{krieger-2022-domain}
\citation{horych-2024-magpie}
\citation{agarap-2018-relu}
\citation{van-1995-python}
\citation{paszke-2017-pytorch}
\citation{wolf-2020-huggingface}
\citation{devlin-2019-bert}
\citation{loshchilov-2019-adamw}
\citation{vscentrum}
\citation{alkhawaldeh-2023-challenges}
\citation{pedregosa-2011-scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Training details}{37}{section.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Class weights in the training set\relax }}{38}{figure.caption.43}\protected@file@percent }
\newlabel{fig:class_weights}{{\M@TitleReference {4.5}{Class weights in the training set\relax }}{38}{Class weights in the training set\relax }{figure.caption.43}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Epochs, learning rate, and warmup steps for proposed methods.\relax }}{38}{table.caption.44}\protected@file@percent }
\newlabel{table:hyperparameters}{{\M@TitleReference {4.3}{Epochs, learning rate, and warmup steps for proposed methods.\relax }}{38}{Epochs, learning rate, and warmup steps for proposed methods.\relax }{table.caption.44}{}}
\@setckpt{chap-4}{
\setcounter{page}{39}
\setcounter{equation}{0}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{49}
\setcounter{lastsheet}{73}
\setcounter{lastpage}{63}
\setcounter{figure}{5}
\setcounter{lofdepth}{1}
\setcounter{table}{3}
\setcounter{lotdepth}{1}
\setcounter{section@level}{1}
\setcounter{Item}{9}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{22}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{parentequation}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
}
