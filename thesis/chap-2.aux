\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{allsides-2022-bias-definition}
\citation{white-1950-case-study-selection-news}
\citation{spinde-2024-taxonomy}
\citation{spinde-2024-taxonomy}
\citation{rodrigo-2024-systematic-review-media-bias}
\citation{eberl-2017-bias-political}
\citation{spinde-2024-taxonomy}
\citation{allsides-media-bias-types}
\citation{spinde-2024-taxonomy}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Background Information and Literature Review}{5}{chapter.2}\protected@file@percent }
\newlabel{cha:2}{{\M@TitleReference {2}{Background Information and Literature Review}}{5}{Background Information and Literature Review}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Media Bias}{5}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Media bias types as defined in The Media Bias Taxonomy \cite  {spinde-2024-taxonomy}\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:media-bias-taxonomy}{{\M@TitleReference {2.1}{Media bias types as defined in The Media Bias Taxonomy \cite  {spinde-2024-taxonomy}\relax }}{5}{Media bias types as defined in The Media Bias Taxonomy \cite {spinde-2024-taxonomy}\relax }{figure.caption.4}{}}
\citation{allsides-media-bias-types}
\citation{allsides-media-bias-types}
\citation{allsides-media-bias-types}
\citation{spinde-2024-taxonomy}
\citation{hube-2019-neural-biased-language}
\citation{spinde-2024-taxonomy}
\citation{mullainathan-2002-media-bias}
\citation{spinde-2024-taxonomy}
\citation{d-alessio-2000-meta-analysis}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of phrasing bias (top), spin bias (middle), and statement bias (bottom) \cite  {allsides-media-bias-types}\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:bias-examples}{{\M@TitleReference {2.2}{Example of phrasing bias (top), spin bias (middle), and statement bias (bottom) \cite  {allsides-media-bias-types}\relax }}{6}{Example of phrasing bias (top), spin bias (middle), and statement bias (bottom) \cite {allsides-media-bias-types}\relax }{figure.caption.5}{}}
\citation{reuters-2023-false-info}
\citation{reuters-2023-false-info}
\citation{yougov-2023-frequency}
\citation{yougov-2023-frequency}
\citation{reuters-2023-false-info}
\citation{yougov-2023-frequency}
\citation{pew-2021-partisan-divides}
\citation{gallup-knight-2020-american-views}
\citation{reuters-2023-digital-news-report}
\citation{gallup-knight-2020-american-views}
\citation{reuters-2023-digital-news-report}
\citation{reuters-2023-trust}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The rate of news consumers witnessing false or misleading information on several recent key topics in February 2023 \cite  {reuters-2023-false-info}\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:consumers-witnessing-false-information-on-certain-topics-worldwide-2023}{{\M@TitleReference {2.3}{The rate of news consumers witnessing false or misleading information on several recent key topics in February 2023 \cite  {reuters-2023-false-info}\relax }}{7}{The rate of news consumers witnessing false or misleading information on several recent key topics in February 2023 \cite {reuters-2023-false-info}\relax }{figure.caption.6}{}}
\citation{reuters-2023-trust}
\citation{reuters-2023-trust}
\citation{allsides}
\citation{adfontes}
\citation{rodrigo-2024-systematic-review-media-bias}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Frequency of seeing false or misleading information online in the United States as of April 2023, by age group \cite  {yougov-2023-frequency}\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:frequency-of-seeing-false-information-online-in-the-us-2023-by-age-group}{{\M@TitleReference {2.4}{Frequency of seeing false or misleading information online in the United States as of April 2023, by age group \cite  {yougov-2023-frequency}\relax }}{8}{Frequency of seeing false or misleading information online in the United States as of April 2023, by age group \cite {yougov-2023-frequency}\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Trustworthiness of news media worldwide by country, as of February 2023 \cite  {reuters-2023-trust}\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:trustworthiness-of-news-media-worldwide-2023}{{\M@TitleReference {2.5}{Trustworthiness of news media worldwide by country, as of February 2023 \cite  {reuters-2023-trust}\relax }}{8}{Trustworthiness of news media worldwide by country, as of February 2023 \cite {reuters-2023-trust}\relax }{figure.caption.8}{}}
\citation{rahul-2023-bow-medium}
\citation{rahul-2023-bow-medium}
\citation{qader-2019-bow}
\citation{camacho-collados-2020-embeddings}
\citation{pennington-2014-glove}
\citation{mikolov-2013-embeddings}
\citation{mikolov-2014-doc2vec}
\citation{white-2015-how-well-sentence-embeddings}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Machine Learning Concepts and Techniques}{9}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Text Representation}{9}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces An illustration of how Bag-of-Words work \cite  {rahul-2023-bow-medium}\relax }}{9}{figure.caption.9}\protected@file@percent }
\newlabel{fig:bow_illustration}{{\M@TitleReference {2.6}{An illustration of how Bag-of-Words work \cite  {rahul-2023-bow-medium}\relax }}{9}{An illustration of how Bag-of-Words work \cite {rahul-2023-bow-medium}\relax }{figure.caption.9}{}}
\citation{narayanan-2019-word-embeddings}
\citation{narayanan-2019-word-embeddings}
\citation{camacho-collados-2020-embeddings}
\citation{liu-2020-survey-contextual-embeddings}
\citation{camacho-collados-2020-embeddings}
\citation{camacho-collados-2020-embeddings}
\citation{perez-enciso-2019-guide}
\citation{perez-enciso-2019-guide}
\citation{rumelhart-1986-ann}
\citation{aws-neural-network}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Word embeddings visualisation \cite  {narayanan-2019-word-embeddings}\relax }}{10}{figure.caption.10}\protected@file@percent }
\newlabel{fig:word-embeddings}{{\M@TitleReference {2.7}{Word embeddings visualisation \cite  {narayanan-2019-word-embeddings}\relax }}{10}{Word embeddings visualisation \cite {narayanan-2019-word-embeddings}\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Neural Networks}{10}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces An illustration of contextualised word embeddings. A language modelling component analyses the context of the target word (as shown in the figure) and generates its dynamic embedding. \cite  {camacho-collados-2020-embeddings}\relax }}{11}{figure.caption.11}\protected@file@percent }
\newlabel{fig:contextualised-word-embeddings}{{\M@TitleReference {2.8}{An illustration of contextualised word embeddings. A language modelling component analyses the context of the target word (as shown in the figure) and generates its dynamic embedding. \cite  {camacho-collados-2020-embeddings}\relax }}{11}{An illustration of contextualised word embeddings. A language modelling component analyses the context of the target word (as shown in the figure) and generates its dynamic embedding. \cite {camacho-collados-2020-embeddings}\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces MultiLayer Perceptron visualisation \cite  {perez-enciso-2019-guide}\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:mlp}{{\M@TitleReference {2.9}{MultiLayer Perceptron visualisation \cite  {perez-enciso-2019-guide}\relax }}{11}{MultiLayer Perceptron visualisation \cite {perez-enciso-2019-guide}\relax }{figure.caption.12}{}}
\citation{uzair-2020-hidden-layers}
\citation{popescue-2009-mlp}
\citation{rahman-2023-lstm-networks}
\citation{rahman-2023-lstm-networks}
\citation{hochreiter-1997-lstm}
\citation{vaswani-2023-attention}
\citation{vaswani-2023-attention}
\citation{lin-2022-survey-transformers}
\citation{vaswani-2023-attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Long Short-Term Memory (LSTM)}{12}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces LSTM architecture \cite  {rahman-2023-lstm-networks}\relax }}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:lstm}{{\M@TitleReference {2.10}{LSTM architecture \cite  {rahman-2023-lstm-networks}\relax }}{12}{LSTM architecture \cite {rahman-2023-lstm-networks}\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Transformer and Large Language Model (LLM)}{12}{subsection.2.2.4}\protected@file@percent }
\citation{devlin-2019-bert}
\citation{openai-2024-gpt4}
\citation{semianalysis-gpt4}
\citation{devlin-2019-bert}
\citation{devlin-2019-bert}
\citation{devlin-2019-bert}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Transformer visualisation \cite  {vaswani-2023-attention}\relax }}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:transformer}{{\M@TitleReference {2.11}{Transformer visualisation \cite  {vaswani-2023-attention}\relax }}{13}{Transformer visualisation \cite {vaswani-2023-attention}\relax }{figure.caption.14}{}}
\citation{lin-2022-survey-transformers}
\citation{makridakis-2017-ai-revolution}
\citation{devlin-2019-bert}
\citation{devlin-2019-bert}
\citation{horych-2024-magpie}
\citation{horych-2024-magpie}
\citation{horych-2024-magpie}
\citation{caruana-1997-mtl}
\citation{aghajanyan-2021-muppet}
\citation{horych-2024-magpie}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces BERT pre-training and fine-tuning procedures \cite  {devlin-2019-bert}\relax }}{14}{figure.caption.15}\protected@file@percent }
\newlabel{fig:bert_finetuning}{{\M@TitleReference {2.12}{BERT pre-training and fine-tuning procedures \cite  {devlin-2019-bert}\relax }}{14}{BERT pre-training and fine-tuning procedures \cite {devlin-2019-bert}\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}MAGPIE and DA-RoBERTa}{14}{subsection.2.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces MAGPIE containing a pre-trained representation of various biases \cite  {horych-2024-magpie}.\relax }}{14}{figure.caption.16}\protected@file@percent }
\newlabel{fig:magpie}{{\M@TitleReference {2.13}{MAGPIE containing a pre-trained representation of various biases \cite  {horych-2024-magpie}.\relax }}{14}{MAGPIE containing a pre-trained representation of various biases \cite {horych-2024-magpie}.\relax }{figure.caption.16}{}}
\citation{krieger-2022-domain}
\citation{devlin-2019-bert}
\citation{sun-2020-fine-tune}
\citation{wu-2021-hi-transformer}
\citation{wu-2021-hi-transformer}
\citation{wu-2021-hi-transformer}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Chunking and Hierarchical Techniques}{15}{subsection.2.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Illustration of chunking\relax }}{15}{figure.caption.17}\protected@file@percent }
\newlabel{fig:chunking}{{\M@TitleReference {2.14}{Illustration of chunking\relax }}{15}{Illustration of chunking\relax }{figure.caption.17}{}}
\citation{wan-2019-long-length}
\citation{borko-1963-auto-doc-classification}
\citation{luhn-1958-business-intelligence-system}
\citation{afzal-deepdocclassifier}
\citation{liu-2017-xmlcnn}
\citation{yang-2016-han}
\citation{adhikari-2019-docbert}
\citation{devlin-2019-bert}
\citation{beltagy-2020-longformer}
\citation{zaheer-2021-bigbird}
\citation{zaheer-2021-bigbird}
\citation{beltagy-2020-longformer}
\citation{park-2022-efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces An example of hierarchical transformer model, Hi-Transformer\cite  {wu-2021-hi-transformer}, to model long document by incorporating information on sentence and word level.\relax }}{16}{figure.caption.18}\protected@file@percent }
\newlabel{fig:hi_transformer}{{\M@TitleReference {2.15}{An example of hierarchical transformer model, Hi-Transformer\cite  {wu-2021-hi-transformer}, to model long document by incorporating information on sentence and word level.\relax }}{16}{An example of hierarchical transformer model, Hi-Transformer\cite {wu-2021-hi-transformer}, to model long document by incorporating information on sentence and word level.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Literature Review}{16}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Document Classification}{16}{subsection.2.3.1}\protected@file@percent }
\citation{pappagari-2019-hierarchical}
\citation{su-2021-classifying}
\citation{adhikari-2019-docbert}
\citation{khandve-2022-hierarchical-longdoc}
\citation{dien-2019-article-classification}
\citation{newswhip-2013-article-length}
\citation{rodrigo-2024-systematic-review-media-bias}
\citation{rodrigo-2024-systematic-review-media-bias}
\citation{rodrigo-2024-systematic-review-media-bias}
\citation{fan-2019-basil}
\citation{chen-2020-nlpcss}
\citation{gruppi-2023-nela-gt-2022}
\citation{mbfc}
\citation{spinde-2023-bat}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Media Bias Classification}{17}{subsection.2.3.2}\protected@file@percent }
\citation{maab-2023-lexical-bias-detection}
\citation{maab-2023-target-aware}
\citation{guo-2022-modeling}
\citation{van-den-berg-2020-context}
\citation{lee-2021-unifying}
\citation{lei-2022-sentence}
\citation{lei-2024-event-relation}
\citation{krieger-2022-domain}
\citation{demidov-2023-political-bias-classification}
\citation{kulkarni-2018-multi-view}
\citation{baly-2020-we-can-detect-your-bias}
\citation{kim-johnson-2022-close}
\citation{chen-2020-detecting-media-bias-gaussian}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Overview of available media bias datasets \cite  {rodrigo-2024-systematic-review-media-bias}\relax }}{18}{figure.caption.19}\protected@file@percent }
\newlabel{fig:media-bias-datasets-overview}{{\M@TitleReference {2.16}{Overview of available media bias datasets \cite  {rodrigo-2024-systematic-review-media-bias}\relax }}{18}{Overview of available media bias datasets \cite {rodrigo-2024-systematic-review-media-bias}\relax }{figure.caption.19}{}}
\@setckpt{chap-2}{
\setcounter{page}{19}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{23}
\setcounter{lastsheet}{58}
\setcounter{lastpage}{54}
\setcounter{figure}{16}
\setcounter{lofdepth}{1}
\setcounter{table}{0}
\setcounter{lotdepth}{1}
\setcounter{section@level}{2}
\setcounter{Item}{4}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{10}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
}
